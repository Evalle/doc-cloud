<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet
 href="urn:x-daps:xslt:profiling:novdoc-profile.xsl" 
 type="text/xml"
 title="Profiling step"?>
<!DOCTYPE chapter PUBLIC "-//Novell//DTD NovDoc XML V1.0//EN" "novdocx.dtd"
[
  <!ENTITY % NOVDOC.DEACTIVATE.IDREF "IGNORE">
  <!ENTITY % entities SYSTEM "entity-decl.ent">
  %entities;
]>

<!--

Deleting a proposal
https://bugzilla.novell.com/show_bug.cgi?id=776970

-->


<chapter id="cha.depl.nodes">
 <title>Deploying the &ostack; Nodes</title>
 <para/>

  <sect1 id="sec.depl.nodes.alloc.barclamps">
   <title>Barclamps</title>
   <para>
    The &ostack; services are deployed onto the nodes by using so-called
    &barcl;s&mdash;a set of recipes, templates and installation
    instructions. All existing &barcl; can be accessed from the &crow; Web interface by clicking on <guimenu>Barclamps</guimenu>. To edit a
    &barcl; proceed as follows:
   </para>
   <procedure>
    <step>
     <para>
      Open a browser and point it to the &crow; Web interface available at port
      <literal>3000</literal> of the &admserv;, for example <ulink
      url="http://192.168.124.10:3000/"/>. Log in as user <systemitem
      class="username">crowbar</systemitem>. The password defaults to
      <literal>crowbar</literal>, if you have not changed it.
     </para>
     <para>
      Click  <guimenu>Barclamps</guimenu> to open the <guimenu>All
      Barclamps</guimenu> menu. Alternatively you may filter the list to
      <guimenu>Crowbar</guimenu> or <guimenu>&ostack;</guimenu> &barcl;s by
      choosing the respective option from <guimenu>Barclamps</guimenu>.
     </para>
    </step>
    <step>
     <para>
      Click a &barcl;'s name. You can either <guimenu>Create</guimenu>
      a proposal or <guimenu>Edit</guimenu> an existing one.
     </para>
     <para>
      When creating a new proposal, give it a
      meaningful name and description. You can create several proposals,
      for example, for testing purposes.
     </para>
     <para>
      Most &barcl;s consist of two sections: the <guimenu>Attributes</guimenu>
      section lets you change the configuration, the <guimenu>Node
      Deployment</guimenu> section lets you choose onto which nodes to deploy
      the &barcl;.
     </para>
    </step>
    <step>
     <para>
      To edit the <guimenu>Attributes</guimenu> section change the values via
      the Web form. Alternatively you can directly edit the configuration file
      by clicking <guimenu>Raw</guimenu>. </para>
      <note><title>Raw Mode</title>
      <para>Only use the <guimenu>Raw</guimenu> mode in case in case an option 
      cannot be changed via Web form. Raw mode does not perform any syntax checks.
     </para>
     </note>
     <para>
      In the <guimenu>Node Deployment</guimenu> section you can drag and
      drop nodes from the <guimenu>Available Nodes</guimenu> column to the
      desired role. You need to drop the node onto the role name. Do
      <emphasis>not</emphasis> drop a node onto the input field, this is
      rather used to filter the list of <guimenu>Available Nodes</guimenu>!
      To remove a node from a role, click the respective
      <guimenu>Remove</guimenu> icon. Sometimes it is necessary to remove a
      node from a certain role before you can assign it to a new role.
     </para>
     <para>
      The <guimenu>Node Deployment</guimenu> can also be changed by editing
      the configuration file in <guimenu>Raw</guimenu> mode.
     </para>
     
     <tip>
      <title>Save Before Switching the Edit Mode</title>
      <para>
       If you switch between <guimenu>Raw</guimenu> mode and Web form
       (<guimenu>Custom</guimenu> mode), make sure to <guimenu>Save</guimenu>
       your changes before switching, otherwise they will be lost.
      </para>
     </tip>
     
    </step>
    <step>
     <para>
      To save and deploy your edits, click <guimenu>Apply</guimenu>. To just
      save your changes without deploying them, click
      <guimenu>Save</guimenu>. To remove the complete proposal, click
      <guimenu>Deactivate</guimenu>. A proposal that already has been deployed
      cannot be deleted, but rather be deactivated.
     </para>
     <para>
      If you deploy a proposal onto a node where a previous one is still
      active, the new proposal will overwrite the old one.
     </para>
    </step>
   </procedure>
   
   <warning>
    <title>Barclamp Deployment Failure</title>
    <para>
     In case the deployment of a &barcl; fails, make sure to fix the reason
     that has caused the failure and deploy the &barcl; again. Refer to the
     respective troubleshooting section for help. A deployment
     failure may leave your node in an inconsistent state.
    </para>
   </warning>
   
 </sect1>

 <sect1 id="sec.depl.nodes.controller">
  <title>Deploying the &contrnode;</title>
  <para>
   The first &ostack; node that needs to be set up is the &contrnode;. In the
   following we assume that you only use one machine to control your
   &cloud;. Alternatively you may deploy the services onto separate controller
   nodes.
  </para>
  <note>
   <title>Scope of Operation</title>
   <para>
    It is perfectly reasonable to deploy all services controlling the cloud
    (including storage management and control services) onto one physical
    machine acting as the &contrnode;. However, you should
    <emphasis>not</emphasis> use your &contrnode; as a compute or storage
    host. Here is a list with services that should <emphasis>not</emphasis> be
    deployed onto the &contrnode;:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      <guimenu>Swift-storage</guimenu>
     </para>
    </listitem>
    <listitem>
     <para>
      <guimenu>&ceph;-store</guimenu>
     </para>
    </listitem>
    <listitem>
     <para>
      <guimenu>Nova-multi-compute</guimenu>
     </para>
    </listitem>
   </itemizedlist>
  </note>
  <para>
   The &ostack; services need to be deployed in a given order, otherwise some 
   services may not work or need to be deployed twice:
  </para>
  <orderedlist>
   <listitem>
   <!--<guimenu>Database</guimenu>-->
    <para>
     <xref linkend="sec.depl.nodes.controller.db" xrefstyle="select:title nopage"/>
    </para>
   </listitem>
   <listitem>
   <!--<guimenu>Keystone</guimenu>-->
    <para>
   <xref linkend="sec.depl.nodes.controller.keystone" xrefstyle="select:title nopage"/>
    </para>
   </listitem>
   <listitem>
   <!--<guimenu>Swift</guimenu> and <guimenu>&ceph;</guimenu> (both optional)-->
    <para>
     <xref linkend="sec.depl.nodes.controller.storage" xrefstyle="select:title nopage"/>
    </para>
   </listitem>
   <listitem>
   <!--<guimenu>Glance</guimenu>-->
    <para>
     <xref linkend="sec.depl.nodes.controller.glance" xrefstyle="select:title nopage"/>
    </para>
   </listitem>
   <listitem>
   <!--<guimenu>Nova</guimenu>-->
    <para>
     <xref linkend="sec.depl.nodes.controller.nova" xrefstyle="select:title nopage"/>
    </para>
   </listitem>
   <listitem>
   <!--<guimenu>Nova Dashboard</guimenu>--> 
    <para>
     <xref linkend="sec.depl.nodes.controller.dash" xrefstyle="select:title nopage"/>
    </para>
   </listitem>
  </orderedlist>
  <para>
   For general instructions on how to edit and deploy &barcl; refer to <xref
   linkend="sec.depl.nodes.alloc.barclamps"/>.
  </para>
  
  <sect2 id="sec.depl.nodes.controller.db">
   <title>Database</title>
   <para>
    The very first service that needs to be deployed is the
    <guimenu>Database</guimenu>. The database service is used by all other
    services. &cloud; only supports <guimenu>&postgres;</guimenu> as an
    <guimenu>SQL Engine</guimenu>, so this value must not be
    changed. <guimenu>Database</guimenu> needs to be deployed onto the
    &contrnode;.
   </para>
  </sect2>

  
  <sect2 id="sec.depl.nodes.controller.keystone">
   <title>Keystone</title>
   <para>
    <guimenu>Keystone</guimenu> is another core component that is used by all
    other &ostack; services. It provides authentication and authorization
    services. <guimenu>Keystone</guimenu> needs to be deployed onto the
    &contrnode;. You can configure the following parameters of this &barcl;:
   </para>
   <variablelist>
    <varlistentry>
     <term><guimenu>SQL Engine</guimenu></term>
     <listitem>
      <para>
       Must be set to <guimenu>&postgres;/MySQL</guimenu>. This is the default.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><guimenu>SQL Instance</guimenu></term>
     <listitem>
      <para>
       Name of the proposal you deployed in the previous step (see <xref
       linkend="sec.depl.nodes.controller.db"/>). The default value should be
       correct. 
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><guimenu>Default Tenant</guimenu></term>
     <listitem>
      <para>
       Tenant for the users. Do not change the default value of
       <literal>openstack</literal>. 
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Regular User/Administrator Username/Password</term>
     <listitem>
      <para>
       Username and password for the regular user and the administrator. Both
       accounts can be used to log into the &cloud; &dash; to manage Keystone users
       and access.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><guimenu>Administrator Token (long-lived)</guimenu></term>
     <listitem>
      <para>
       The permanent administrator token (random string).
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><guimenu>Administrator Token Expiration</guimenu></term>
     <listitem>
      <para>
       Expiration Date for the administrator token. Must be entered in the
       form
       <replaceable>YYYY-MM-DD</replaceable>T<replaceable>HH:MM</replaceable>,
       e.g. 2015-03-31T12:00.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><guimenu>Security Attributes</guimenu></term>
     <listitem>
      <para>
       When sticking with the default value <literal>HTTP</literal>, public
       communication will not be encrypted. Choose <literal>HTTPS</literal> to
       use SSL for encryption and specify the path to the certificate
       files. Note that you need to create and copy the certificate prior to
       deploying Keystone, see <xref linkend="sec.depl.inst.nodes.post.ssl"/>
       for instructions.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
  </sect2>
 
  <sect2 id="sec.depl.nodes.controller.storage">
   <title>Swift and &ceph; (both optional)</title>
   <para>
    Detailed instructions on the <guimenu>Swift</guimenu> and
    <guimenu>&ceph;</guimenu> deployment are available at <xref
    linkend="sec.depl.nodes.storage"/>. Although recommended, deploying these
    two services is optional&mdash;a basic block-storage service without
    redundancy can also be provided by nova-volume.
   </para>
   <para>
    Swift and &ceph; each have a storage role (<guimenu>&ceph;-store</guimenu>
    or <guimenu>Swift-storage</guimenu>), which should be deployed on the &stornode;s. 
    Apart from that, both Swift and &ceph; need additional management 
    roles, which should be deployed onto the &contrnode;:
   </para>
   <variablelist>
    <varlistentry>
     <term><guimenu>Swift-ring-compute</guimenu></term>
     <listitem>
      <para>
       The ring maintains the information about the location of objects,
       replicas, and devices. It can be compared to an index, that is used by
       various &ostack; services to look up the physical location of objects.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><guimenu>Swift-proxy-acct</guimenu></term>
     <listitem>
      <para>
       The Swift proxy server takes care of routing requests to Swift.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><guimenu>&ceph;-mon-master</guimenu></term>
     <listitem>
      <para>
       Master Management node for &ceph;. An additional two or four nodes also
       need to run the <guimenu>&ceph;-mon</guimenu> service. The sum of the
       <guimenu>&ceph;-mon-master</guimenu> and the <guimenu>&ceph;-mon</guimenu>
       nodes must always be an odd number.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
   <note>
    <title>Nova Volume</title>
    <para>
     When &ceph; is deployed, Nova Volume, which runs on the &contrnode;, will
     automatically use &ceph;. If you choose to not deploy &ceph;, you must make
     sure to provide enough disk space on the &contrnode;.
    </para>
   </note>
  </sect2>
  <sect2 id="sec.depl.nodes.controller.glance">
   <title>Glance</title>
   <para>  
    Glance provides discovery, registration, and delivery services for virtual
    disk images. An image is needed to start a &vmguest;&mdash; it is its
    pre-installed root-partition. All images you want to use in your cloud to
    boot &vmguest;s from, are provided by Glance.
   </para>
   <para>
    Glance should be deployed onto the &contrnode;. There are a lot of options
    to configure Glance. The most important ones are explained below&mdash;for
    a complete reference refer to <ulink url="https://github.com/dellcloudedge/crowbar/wiki/Glance--barclamp"/>. 
   </para>
   <variablelist>
    <varlistentry>
     <term><guimenu>Image Store Directory</guimenu></term>
     <listitem>
      <para>
       Directory in which all images uploaded to Glance are stored. If you
       want to put the images onto a separate partition or volume, you need to
       mount this partition or volume on the &contrnode; prior to deploying
       the Glance proposal. Specify the mount point of the partition or volume
       here. 
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><guimenu>Security Attributes</guimenu></term>
     <listitem>
      <para>
       When sticking with the default value <literal>HTTP</literal>, public
       communication will not be encrypted. Choose <literal>HTTPS</literal> to
       use SSL for encryption and specify the path to the certificate
       files. Note that you need to create and copy the certificate prior to
       deploying Glance, see <xref linkend="sec.depl.inst.nodes.post.ssl"/>
       for instructions.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>API/Registry <guimenu>Bind to All Addresses</guimenu></term>
     <listitem>
      <para>
       Set these two options to <literal>true</literal> to enable image
       uploads to Glance.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><guimenu>Caching</guimenu></term>
     <listitem>
      <para>
       Enable and configure image caching in this section. By default image
       caching is disabled. Learn more about Glance's caching feature at
       <ulink url="http://docs.openstack.org/developer/glance/cache.html"/>.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
  </sect2>
  
  <sect2 id="sec.depl.nodes.controller.nova">
   <title>Nova</title>
   <para>     
     Detailed instructions on the <guimenu>Nova</guimenu> deployment are
     available at <xref linkend="sec.depl.nodes.compute"/>. The Nova &barcl;
     deploys two roles: <guimenu>Nova-multi-controller</guimenu> and
     <guimenu>Nova-multi-compute</guimenu>. While the latter needs to be
     deployed onto the &compnode;s, <guimenu>Nova-multi-controller</guimenu>
     needs to be deployed onto the &contrnode;.
   </para>
  </sect2>
  
  <sect2 id="sec.depl.nodes.controller.dash">
   <title>Nova Dashboard</title>
   <para>     
    The last service that needs to be deployed is the Nova Dashboard. It
    provides a Web interface for users to start and stop &vmguest;s and for
    administrators to manage users, groups, roles, etc. Nova Dashboard should
    be deployed onto the &contrnode;. The following attributes can be
    configured:
   </para>
   <variablelist>
    <varlistentry>
     <term><guimenu>SQL Engine</guimenu></term>
     <listitem>
      <para>
       Must be set to <guimenu>&postgres;/MySQL</guimenu>. This is the default.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>SQL/Keystone Instance</term>
     <listitem>
      <para>
       Name of the proposal for <guimenu>Database</guimenu> and
       <guimenu>Keystone</guimenu> you deployed in the previous steps. The
       default value should be correct.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><guimenu>Disable SSL Certification Verification</guimenu></term>
     <listitem>
      <para>
       Should always be set to <literal>false</literal> (default) in
       production environments. Only use it for testing purposes.
      </para>
     </listitem>
    </varlistentry>
    
    <varlistentry>
     <term><guimenu>Apache Attributes</guimenu></term>
     <listitem>
      <para>
       When sticking with the default value <guimenu>HTTP</guimenu> equals
       <literal>true</literal>, public communication will not be
       encrypted. Set <literal>HTTPS</literal> to <literal>true</literal> to
       use SSL for encryption and specify the path to the certificate
       files. Note that you need to create and copy the certificate prior to
       deploying Keystone, see <xref linkend="sec.depl.inst.nodes.post.ssl"/>
       for instructions.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
  </sect2>  
 </sect1>

 <sect1 id="sec.depl.nodes.compute">
  <title>&compnode;</title>
  <para>
   The &compnode;s are the <quote>workhorses</quote> of the cloud&mdash;each
   &vmguest;s is started on a &compnode;. This functionality is provided by
   the <guimenu>Nova-multi-compute</guimenu> role that needs to be deployed
   onto every &compnode; via the Nova &barcl;. Distributing and scheduling
   the &vmguest;s is managed by the <guimenu>Nova-multi-controller</guimenu>
   role that needs to be deployed onto the &contrnode;.
  </para>
  <para>
   There are a lot of options to configure Nova. The most important ones are
   explained below&mdash;for a complete reference refer to <ulink
   url="https://github.com/dellcloudedge/crowbar/wiki/Nova--barclamp"/>. You
   will also find details about Nova's network modes on that page.
  </para>
  <variablelist>
   <varlistentry>
    <term><guimenu>Hypervisor</guimenu></term>
    <listitem>
     <para>
      Choose between the <literal>KVM</literal> and <literal>Xen</literal>
      hypervisors. At the moment &productname; does not support choosing more
      than one hypervisor.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Choose disks for nova-volume storage volume group</term>
    <listitem>
     <para>
      In case you have not deployed &ceph;, you need to use Nova Volume for
      block storage (refer to <xref linkend="sec.depl.nodes.storage"/> for
      more information on storage). Specify which disks to use with this
      option. If &ceph; was already deployed, it is used automatically and you
      will not be able to choose any disks here.
     </para>
     
     <note>
      <title>Nova Volume</title>
      <para>
       Nova Volume only runs on the host onto which
       <guimenu>Nova-multi-controller</guimenu> is deployed. Make sure it is
       equipped with enough spare disks.
      </para>
     </note>
     
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><guimenu>Security Attributes</guimenu></term>
    <listitem>
     <para>
      When sticking with the default value <literal>HTTP</literal>, public
      communication will not be encrypted. Choose <literal>HTTPS</literal> to
      use SSL for encryption and specify the path to the certificate
      files. Note that you need to create and copy the certificate prior to
      deploying Nova, see <xref linkend="sec.depl.inst.nodes.post.ssl"/>
      for instructions.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>noVNC Security Attributes</term>
    <listitem>
     <para>
      After having started a &vmguest; you can display its VNC console in the
      Nova &dash; via browser using the <literal>noVNC</literal>
      implementation. By default this connection is not encrypted and can
      potentially be eavesdropped. To encrypt it, you can make use of SSL by
      setting <guimenu>noVNC via SSL</guimenu> to <literal>true</literal>. If
      you do not specify any additional certificates, the same ones as for
      Nova (see previous step) will be used.<remark>taroth 2012-08-20: fs, it is
      unclear what you mean with "previous step" here</remark>
     </para>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>

 <sect1 id="sec.depl.nodes.storage">
  <title>Deploying the &stornode;</title>
  <para>
   &ostack; provides two storage services: block-storage (&ceph;) and object
   storage (Swift). Block storage is used to store persistent devices that can
   be mounted from &vmguest;s. Object storage is used to store single files
   such as images or snapshots.
  </para>
  <para>
   Both storage services offer high data security by storing the data
   redundant upon a pool of &stornode;s. Deploying &ceph; and Swift is
   optional, but highly recommended. Block storage can alternatively be
   provided by Nova Volume, but Nova Volume offers neither redundancy nor
   distributed storage (Nova Volume solely runs on the &contrnode;). When &ceph;
   is deployed, Nova Volume automatically makes use of it.
  </para>
  <para>
   In order to provide redundancy you need at least two dedicated nodes for
   each of the services. It is not possible to deploy the &ceph; and Swift
   storage services onto the same machine! All &stornode;s need at least two
   disks. All disks that should be used for storage must be unmounted.
  </para>
  
  <warning>
   <title>&ceph; and Swift Need Dedicated Machines</title>
   <para>
    Never deploy Swift and &ceph; storage services (<guimenu>&ceph;-store</guimenu>,
    <guimenu>Swift-storage</guimenu>) onto the same node!
   </para>
  </warning>

  <sect2 id="sec.depl.nodes.compute.ceph">
   <title>Deploying &ceph;</title>
   <para>
    The &ceph; &barcl; only has one configuration option: telling &ceph; which
    devices to use on the nodes. Edit the &barcl; in <guimenu>Raw</guimenu>
    and search for the following the lines
   </para>
   <screen>  "devices": [
   
  ],</screen>
   <para>
    Add a comma-separated list of devices that should be used by &ceph;. For
    example: 
   </para>
   <screen>  "devices": [
    "/dev/sdb", "/dev/sdc", "/dev/sdd"
  ],</screen>
  
   <important>
    <title>Devices</title>
    <para>
     Not all of the devices used for &ceph; need to exist on all nodes. All
     devices matching the list configured in the &barcl; must 
     <emphasis>not</emphasis> be mounted. Any data stored on these devices will 
     be lost.
    </para>
   </important>
   
   <para>
    You need to deploy three different roles for
    &ceph;. <guimenu>&ceph;-store</guimenu> should be deployed to all &stornode;s 
    dedicated to &ceph;. The minimum number of nodes is two. It is
    recommended to deploy <guimenu>&ceph;-mon-master</guimenu> onto the
    &contrnode;. <guimenu>&ceph;-mon</guimenu> should be deployed onto two of the
    &stornode;s. Note that you can not delete or deallocate the nodes hosting
    <guimenu>&ceph;-mon</guimenu> at a later stage. To deploy &ceph; proceed as
    follows:  
   </para>
   <procedure>
   <important><para>The steps must be performed in the given order!</para></important>
    <step>
     <para>
      Edit the &barcl; proposal to specify the devices to be used by &ceph; as
      described above.
     </para>
    </step>
    <step>
     <para>
      Drag and drop a node (for example, the &contrnode;) to the
      <guimenu>&ceph;-mon-master</guimenu> role.
      role. 
     </para>
    </step>
    <step>
     <para>
      Drag and drop two or four nodes to the <guimenu>&ceph;-mon</guimenu>
      role. Note that the maximum number of <guimenu>&ceph;-mon</guimenu> nodes
      cannot exceed four and that the sum of <guimenu>&ceph;-mon-master</guimenu>
      and <guimenu>&ceph;-mon</guimenu> nodes must be odd.
     </para>
    </step>
    <step>
     <para>
      Drag and drop all dedicated &ceph; &stornode;s to the
      <guimenu>&ceph;-store</guimenu> (at least two). You may also use the nodes
      with the <guimenu>&ceph;-mon</guimenu> roles, but not the
      <guimenu>&ceph;-mon-master</guimenu> node (you can add that one later).
     </para>
    </step>
    <step>
     <para>
      Click <guimenu>Apply</guimenu> to deploy your proposal. This can take some
      time.  
     </para>
    </step>
    <step>
     <para>
      If you also want to use the <guimenu>&ceph;-mon-master</guimenu> as a
      &stornode;, drag and drop it to the <guimenu>&ceph;-store</guimenu>
      role and click <guimenu>Apply</guimenu> again. Note that it is not
      recommended to use the &contrnode; for non-management purposes such as
      storage or compute.
     </para>
    </step>
   </procedure>
  </sect2>

  <sect2 id="sec.depl.nodes.compute.swift">
   <title>Deploying Swift</title>
   <para>
    Swift always uses all unmounted disks that are available on the &stornode;s. It
    is recommended to not change the defaults in the &barcl; proposal (except
    from the <guimenu>Cluster Admin Password</guimenu>) unless
    you exactly know what you are doing. Note that you need at least as many
    &stornode;s as <guimenu>Zones</guimenu> (default: 2).
   </para>
   <para>
    It is recommended to deploy the roles
    <guimenu>Swift-ring-compute</guimenu> and
    <guimenu>Swift-proxy-acct</guimenu> onto the &contrnode;. Deploy
    <guimenu>Swift-storage</guimenu> onto all dedicated Swift &stornode;s.
   </para>
  </sect2>
 </sect1>
</chapter>
