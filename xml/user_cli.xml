<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet
 href="urn:x-daps:xslt:profiling:novdoc-profile.xsl" 
 type="text/xml"
 title="Profiling step"?>
<!DOCTYPE chapter PUBLIC "-//Novell//DTD NovDoc XML V1.0//EN" "novdocx.dtd"
[
  <!ENTITY % NOVDOC.DEACTIVATE.IDREF "IGNORE">
  <!ENTITY % entities SYSTEM "entity-decl.ent">
  %entities;
]>
<chapter id="cha.user.cli">
 <title>Using &ostack; Command Line Interfaces</title>
 <abstract>
  &cli-descr-short;
 </abstract>
<!--taroth 2012-07-31: implementation of unified command lines tools is WIP:
  http://wiki.openstack.org/UnifiedCLI, 
  http://wiki.openstack.org/UnifiedCLI/Mapping, 
  http://wiki.openstack.org/UnifiedCLI/HumanInterfaceGuidelines,
  glance client  is part of that unifcation effort-->
 <sect1 id="cha.user.cli.oview">
  <title>&ostack; Commands&mdash;Overview</title>
  &openstack-python-tools;
  <!-- <para>
   The &ostack; project currently aims to unify the multiple command line
   tools. For details, refer to
   <ulink url="http://wiki.openstack.org/UnifiedCLI"/> and
   <ulink url="http://wiki.openstack.org/UnifiedCLI/Mapping"/>. Commands for
   tasks that may also may executed from outside the cloud have recently
   been moved to the
   <literal>openstack-</literal>&nbsp;<replaceable>SERVICENAME</replaceable>
   packages.
   <remark>taroth 2012-08-06: DEVs is the following correct?</remark>
   Therefore, divergent variants of the command line tools are currently
   available: the older ones are contained in the packages
   <literal>openstack-</literal>&nbsp;<replaceable>SERVICENAME</replaceable>,
   the newer ones in the packages
   <literal>python-<replaceable>SERVICENAME</replaceable>client</literal>.
   </para> -->

<!--As those packages conflict, you cannot install both variants of a command
   in parallel.-->
 </sect1>
 <sect1 id="sec.user.cli.rc">
  <title>&ostack; RC File</title>
  &rc-file-usage;
 </sect1>
 <sect1 id="sec.user.cli.img">
  <title>Managing Images</title>

   &images;

   &img-manage;

   &img-ownership;

  <para>
   Images can either be uploaded to &productname; with the
   <command>glance</command> command line tool or with the &productname;
   &dash;. As the &dash; comes with some limitations with regards to image
   upload and modification of properties, it is recommended to use the
   <command>glance</command> command line tools for comprehensive image
   management.
  </para>

  <para>
   For detailed information, refer to <xref linkend="sec.adm.cli.img"
   />.
  </para>
 </sect1>
<!--taroth 2013-09-03: disabling for now as there was no feedback/input on the network sections 
  in the UI chapters, therefore it does not make sense to include a further piece
  of crystal ball writing here...->
  <sect1 id="sec.user.cli.networks">
  <title>Managing Networks</title>
  <para>&wip;</para>
  </sect1>-->
 <sect1 id="sec.user.cli.inst.launch">
  <title>Launching Instances</title>
  &instances;
   <para>
   When starting an instance, you need to specify the following key
   parameters:
  </para>

  <variablelist>
   <varlistentry>
    <term>Flavor</term>
    <listitem>
     &flavors;
     <para>
      For more details and a list of default flavors available, refer to
      <xref linkend="sec.adm.cli.flavors"/>.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Keypair</term>
    <listitem>&keypairs;
   <para>
      For details, refer to <xref linkend="sec.user.cli.inst.access.keys"/>.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Security Group</term>
    <listitem>&security;
     <para>
      For details, refer to
      <xref linkend="sec.user.cli.inst.access.security"/>.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Network</term>
    <listitem>
     <para>
      Instances can belong to one or multiple networks. By default, each
      instance is given a fixed IP address, belonging to the internal
      network.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>

  <para>
   If needed, you can assign a floating (public) IP address to a running
   instance and attach a block storage device (<literal>volume</literal>)
   for persistent storage. For details, refer to
   <xref linkend="sec.user.cli.inst.access.ips"/>.
<!--taroth 2012-10-15: FIXME,
   reactivate link after finishing the chapter...-->
<!--and 
  <xref linkend="sec.user.cli.volumes"/>.-->
  </para>

  <para>
   Before you can launch an instance, you need to look up a few parameters,
   for example, which images, flavors, and security groups are available.
   Proceed as follows:
  </para>

  <procedure>
   <title>Launching an Instance</title>
   <step>
    <para>
     On a shell, source the &ostack; RC file. For details, refer to
     <xref linkend="sec.user.cli.rc"/>.
    </para>
   </step>
   <step>
    <para>
     Look up the available flavors:
    </para>
<screen>nova flavor-list</screen>
    <para>
     Memorize the ID of the flavor that you want to use for your instance.
    </para>
   </step>
   <step>
    <para>
     Look up the available images:
    </para>
<screen>nova image-list</screen>
    <para>
     Memorize the ID of the image that you want to boot your instance from.
    </para>
   </step>
   <step>
    <para>
     Look up the available security groups:
    </para>
<screen>neutron security-group-list</screen>
    <para>
     If you have not created any specific security groups, you can only
     assign the instance to the default security group.
    </para>
   </step>
   <step>
    <para>
     Look up your keypair's name (for SSH access) and memorize it:
    </para>
<screen>nova keypair-list</screen>
   </step>
   <step>
    <para>
     Now you have all the parameters at hand for starting an instance. Do so
     with the following command:
    </para>
<screen>nova boot --flavor&nbsp;<replaceable>FLAVOR_ID</replaceable>&nbsp;--image<replaceable>IMAGE_ID</replaceable> --key_name <replaceable>KEY_NAME</replaceable> \
--security_group <replaceable>NAME_OF_SEC_GROUP</replaceable> <replaceable>NAME_FOR_INSTANCE</replaceable>&nbsp;</screen>
    <para>
     The command returns a list of instance properties, including the
     <literal>status</literal> of the instance. The status
     <literal>BUILD</literal> indicates that the instance has started, but
     is not yet online.
    </para>
   </step>
   <step>
    <para>
     Check if the instance is online:
    </para>
<screen>nova list</screen>
    <para>
     This command lists all instances of the project you belong to,
     including their ID, their name, their status, and their private (and if
     assigned, their public) IP addresses. If your instance's status is
     <literal>ACTIVE</literal>, the instance is online.
    </para>
    <para>
     To refine the search, run <command>nova help list</command> to view the
     available options for the command.
    </para>
   </step>
  </procedure>

  <para>
   If you did not provide a keypair on starting and have not touched
   security groups or rules so far, by default the instance can only be
   accessed from inside the cloud via VNC at this point. Even pinging the
   instance is not possible. To change this, proceed with
   <xref linkend="sec.user.cli.inst.access"/>.
  </para>
 </sect1>
 <sect1 id="sec.user.cli.inst.access">
  <title>Configuring Access to the Instances</title>
  &inst-access-params;
  
  <sect2 id="sec.user.cli.inst.access.security">
   <title>Configuring Security Groups and Rules</title>
   &security;
   <sect3 id="sec.user.cli.inst.access.security.groups">
    <title>Security Groups</title>
    &sec-groups;
    
    <para>
     Security groups can now be managed with the
     <command>neutron&nbsp;security-group*</command> commands, provided by
     the <systemitem>python-quantumclient</systemitem> package.
     Alternatively, you can still use the known <command>nova
     secgroup_*-rule</command> commands, provided by the
     <systemitem>python-novaclient</systemitem> package.
    </para>
    <variablelist>
     <varlistentry>
      <term>Listing Security Groups</term>
      <listitem>
<!--<screen>nova secgroup-list</screen>-->
<screen>neutron security-group-list --tenant_id&nbsp;<replaceable>PROJECT_ID</replaceable>&nbsp;</screen>
       <para>
        Lists all security groups for the specified project, including the
        groups' descriptions.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Creating a Security Group</term>
      <listitem>
<!--<screen>nova secgroup-create&nbsp;<replaceable>SEC_GROUP_NAME</replaceable>&nbsp;<replaceable>GROUP_DESCRIPTION</replaceable>&nbsp;</screen>-->
<screen>neutron security-group-create&nbsp;<replaceable>SEC_GROUP_NAME</replaceable>&nbsp;<replaceable>GROUP_DESCRIPTION</replaceable>&nbsp;</screen>
       <para>
        Creates a new security group with the specified name and
        description.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Deleting a Security Group</term>
      <listitem>
<!--<screen>nova secgroup-delete&nbsp;<replaceable>SEC_GROUP_NAME</replaceable>&nbsp;</screen>-->
<screen>neutron security-group-delete&nbsp;<replaceable>SEC_GROUP_NAME_OR_ID</replaceable>&nbsp;</screen>
       <para>
        Deletes the specified group.
       </para>
      &note-groups-delete;
      </listitem>
     </varlistentry>
    </variablelist>
   </sect3>
   <sect3 id="sec.user.cli.inst.access.security.rules">
    <title>Security Group Rules</title>
    &sec-rules;
    
    &sec-rules-params;
    
    &security-default;
   
    <!--taroth 2012-08-27: IIRC, I read this in upstream docs, but according to
     bmwiedemann's tests, he could not access arbitrary ports of VMs in the same
     security group, therefore commenting-->
<!--Unless you change the rules for the default group, this means that
     those instances are only accessible from IP addresses belonging to other members 
     of this group.-->
    <procedure>
     <title>Configuring Security Group Rules</title>
     <para>
      Security group rules can now be modified with the
      <command>neutron&nbsp;security-group-rule*</command> commands,
      available from the
      <systemitem class="resource">python-quantumclient</systemitem>
      package. Alternatively, you can still use the known <command>nova
      &nbsp;secgroup_*-rule</command> commands, provided by the
      <systemitem>python-novaclient</systemitem> package. Proceed as
      follows:
     </para>
     <step>
      <para>
       On a shell, source the &ostack; RC file. For details, refer to
       <xref
        linkend="sec.user.cli.rc"/>.
      </para>
     </step>
     <step>
      <para>
       Look up the existing rules for a security group:
      </para>
<!--<screen>nova secgroup-list-rules <replaceable>SEC_GROUP_NAME</replaceable>&nbsp;</screen>-->
<screen>neutron security-group-rule-list&nbsp;<replaceable>SEC_GROUP_NAME</replaceable>&nbsp;</screen>
      <remark>taroth 2013-09-03: strange, I could not find any option such as tenant_id or
       sec_group_name in the options - check!</remark>
     </step>
     <step>
      <para>
       To enable SSH access to the instances:
      </para>
      <substeps>
       <step id="step.sec.rule.add">
        <para>
         Either from <emphasis>all</emphasis> IP addresses (specified as IP
         subnet in CIDR notation as <literal>0.0.0.0/0</literal>):
        </para>
<!--<screen>nova secgroup-add-rule <replaceable>SEC_GROUP_NAME</replaceable> tcp 22 22 0.0.0.0/0</screen>-->
<screen>neutron&nbsp;security-group-rule-create&nbsp;--direction&nbsp;ingress \
  --protocol&nbsp;tcp&nbsp;--port_range_min&nbsp;22&nbsp;--port_range_max&nbsp;22 \
  <replaceable>SEC_GROUP_NAME_OR_ID</replaceable>&nbsp;</screen>
<!--taroth 2013-07-30: CAVE: nova had 2 commands: secgroup-add-group-rule and secgroup-add-rule (for access by other tenants and access from
         outside, respectively), in quantum there only seems to be one command for both...-->
       </step>
       <step id="step.sec.group.rule.add">
        <para>
         Alternatively, you can allow only IP addresses from other security
         groups (<literal>source groups</literal>) to access the specified
         port:
        </para>
<!--<screen>nova secgroup-add-group-rule -/-ip_proto tcp -/-from_port 22 \
-/-to_port 22 <replaceable>SEC_GROUP_NAME</replaceable>&nbsp;<replaceable>SOURCE_GROUP_NAME</replaceable>&nbsp;</screen>-->
<screen>neutron&nbsp;security-group-rule-create&nbsp;--direction&nbsp;ingress \
  --protocol&nbsp;tcp&nbsp;--port_range_min&nbsp;22&nbsp;--port_range_max&nbsp;22&nbsp; \
  --remote-group-id&nbsp;SOURCE_GROUP_NAME_OR_ID&nbsp;<replaceable>SEC_GROUP_NAME_OR_ID</replaceable>&nbsp;</screen>
       </step>
      </substeps>
     </step>
     <step>
      <para>
       To enable pinging the instances:
      </para>
      <substeps>
       <step>
        <para>
         Either from <emphasis>all</emphasis> IP addresses (specified as IP
         subnet in CIDR notation as <literal>0.0.0.0/0</literal>):
        </para>
<!--<screen>nova secgroup-add-rule <replaceable>SEC_GROUP_NAME</replaceable> icmp -1 -1 0.0.0.0/0</screen>-->
<screen>neutron security-group-rule-create --protocol icmp --direction ingress &nbsp;<replaceable>SEC_GROUP_NAME_OR_ID</replaceable>&nbsp; </screen>
        <remark>taroth 2013-09-03: DEVs - I added the command above according to
         http://docs.openstack.org/trunk/openstack-network/admin/content/enabling_ping_and_ssh.html,
         but I'm wondering if the following might be missing?
         "--port_range_min&nbsp;1&nbsp;--port_range_max&nbsp;1"</remark>
        <para>
         This command allows access to all codes and all types of ICMP
         traffic, respectively.
        </para>
       </step>
       <step>
        <para>
         Alternatively, you can allow only members of other security groups
         (<literal>source groups</literal>) to ping instances:
        </para>
<!--<screen>nova secgroup-add-group-rule -/-ip_proto icmp -/-from_port -1 \
-/-to_port -1
<replaceable>SEC_GROUP_NAME</replaceable>&nbsp;<replaceable>SOURCE_GROUP_NAME</replaceable>&nbsp;</screen>-->
<screen>neutron security-group-rule-create --protocol icmp --direction ingress \
  --remote-group-id&nbsp;SOURCE_GROUP_NAME_OR_ID&nbsp;<replaceable>SEC_GROUP_NAME_OR_ID</replaceable>&nbsp; </screen>
       </step>
      </substeps>
     </step>
     <step>
      <para>
       To allow access via UDP port (for example, for a DNS server running
       on a VM):
      </para>
      <substeps>
       <step>
        <para>
         Either from <emphasis>all</emphasis> IP addresses (specified as IP
         subnet in CIDR notation as <literal>0.0.0.0/0</literal>):
        </para>
<screen>nova secgroup-add-rule <replaceable>SEC_GROUP_NAME</replaceable> udp 53 53 0.0.0.0/0</screen>
        <remark>taroth 2013-09-03: unfortunately, couldn't find out what the respective quantum
         command is, therefore left the nova command for now... </remark>
       </step>
       <step>
        <para>
         Alternatively, you can allow only IP addresses from other security
         groups (<literal>source groups</literal>) to access the specified
         port:
        </para>
<screen>nova secgroup-add-group-rule --ip_proto udp --from_port 53 \
--to_port 53 <replaceable>SEC_GROUP_NAME</replaceable>&nbsp;<replaceable>SOURCE_GROUP_NAME</replaceable>&nbsp;</screen>
        <remark>taroth 2013-09-03: unfortunately, couldn't find out what the respective quantum
         command is, therefore left the nova command for now... </remark>
       </step>
      </substeps>
     </step>
     <step>
      <para>
       To delete a security group rule:
      </para>
<screen>neutron security-group-rule-delete <replaceable>SEC_GROUP_ID</replaceable></screen>
     </step>
<!--taroth 2013-09-03: it seems the following is no longer needed, see
      http://docs.openstack.org/trunk/openstack-network/admin/content/securitygroup_workflow.html,
     therefore commenting-->
<!-- <step>
      <para>
      To delete security group rules, you need to specify the same
      arguments that you used to create the rule. For example:
      </para>
      <para>
      To delete the security rule that you created in
      <xref linkend="step.sec.rule.add"/>:
      </para>
      <screen>nova secgroup-delete-rule <replaceable>SEC_GROUP_NAME</replaceable>&nbsp;tcp 22 22 0.0.0.0/0</screen>
      <para>
      To delete the security rule that you created in
      <xref linkend="step.sec.group.rule.add"/>:
      </para>
      <screen>nova secgroup-delete-group-rule -/-ip_proto tcp -/-from_port 22 \
      -/-to_port 22 <replaceable>SEC_GROUP_NAME</replaceable>&nbsp;<replaceable>SOURCE_GROUP_NAME</replaceable>&nbsp;</screen>
      </step>-->
    </procedure>
<!--taroth 2012-10-12: maybe integrate some of the following information:
   
    Every security group rule is a policy which allows you to specify inbound 
    connections that are allowed to access the instance, by source address, 
    destination port and IP protocol,(TCP, UDP or ICMP). 
    
    Currently, ipv6 and other protocols cannot be managed with the security rules, 
    making them permitted by default. To manage such, you can deploy a firewall 
    in front of your OpenStack cloud to control other types of traffic. The command 
    requires the following arguments for both TCP and UDP rules :
    
              
   [Note]	The CIDR notation
             
   That notation allows you to specify a base IP address and a suffix that designates 
   the number of significant bits in the IP address used to identify the network. 
   For example, by specifying a 88.170.60.32/27, you specify 88.170.60.32 
   as the base IP and 27 as the suffix. Since you use an IPV4 format, there are only 
   5 bits available for the host part (32 minus 27). 
   The 0.0.0.0/0 notation means you allow the entire IPV4 range, meaning allowing all addresses.
              
   For example, in order to allow any IP address to access to a web server running on one of your 
   instance inside the default security group:
   $ nova secgroup-add-rule default tcp 80 80 0.0.0.0/0
              
   In order to allow any IP address to ping an instance inside the default security group 
   (Code 0, Type 8 for the ECHO request.):
    $ nova secgroup-add-rule default icmp 0 8 0.0.0.0/0-->
<!--taroth 2012-08-15: mention when non-default sec groups are useful (info
    by mvidner, for CLI chapter mention how to change security groups for running 
    instances, info by cthiel: 
    sure, this is possible, but AFAIK only through the command-line:
    
    usage: nova add-secgroup <server> <secgroup>
    Add a Security Group to a server.
    
    Positional arguments:
    <server>    Name or ID of server.
    <secgroup>  Name of Security Group.
    
    
    usage: nova remove-secgroup <server> <secgroup>
    
    Remove a Security Group from a server.
    
    Positional arguments:
    <server>    Name or ID of server.
    <secgroup>  Name of Security Group.
   
    
    taroth 2012-10-12: todo - find out if these commands are also part of 
    python-novaclient-->
   </sect3>
  </sect2>

  <sect2 id="sec.user.cli.inst.access.keys">
   <title>Creating or Importing Keys</title>
   &keypairs;
   <para>
    In case an image uses a static &rootuser; password or a static key set
    (neither is recommended), you do not need to provide a keypair on
    starting of the instance.
   </para>
   <procedure>
    <title>Creating or Importing Keys</title>
    <para>
     Use the <command>nova keypair-add</command> command to generate a new
     keypair, or to upload an existing public key.
    </para>
    <step>
     <para>
      To generate a new keypair, execute the following commands:
     </para>
<screen>nova keypair-add <replaceable>KEY_NAME</replaceable> &gt; <replaceable>MY_KEY</replaceable>.pem
      chmod 600  <replaceable>MY_KEY</replaceable>.pem</screen>
     <para>
      The first command generates a new keypair named
      <replaceable>KEY_NAME</replaceable>, writing the private key to the
      file <filename><replaceable>MY_KEY</replaceable>.pem</filename> and
      registering the public key at the &comp; database. The second command
      changes the permissions of the file
      <filename><replaceable>MY_KEY</replaceable>.pem</filename> so that
      only you can read and write to it.
     </para>
    </step>
    <step>
     <para>
      If you already have generated a keypair, with the public key located
      at <filename>~/.ssh/id_rsa.pub</filename>, you can upload the public
      key with the following command:
     </para>
<screen>nova keypair-add --pub_key ~/.ssh/id_rsa.pub <replaceable>KEY_NAME</replaceable>&nbsp;</screen>
     <para>
      The command registers the public key at the &comp; database and names
      the keypair <replaceable>KEY_NAME</replaceable>.
     </para>
    </step>
    <step>
     <para>
      Check if the uploaded keypair appears in the list of available
      keypairs:
     </para>
<screen>nova keypair-list</screen>
    </step>
   </procedure>
  </sect2>

  <sect2 id="sec.user.cli.inst.access.ips">
   <title>Managing IP Addresses</title> 
   &ip-addr; 
   &ip-allocate; 
   &ip-assign; <!-- Pools of floating IP addresses are created outside of python-novaclient with the 
    nova-manage floating * commands. Refer to "Configuring Public (Floating) IP Addresses" 
    in the Openstack &comp; Administration Manual for more information.-->
   <para>
    Floating IP addresses can be managed with the <command>neutron</command>
    commands, provided by the <systemitem>python-quantumclient</systemitem>
    package. Alternatively, you can still use the known
    <command>nova</command> commands, provided by the
    <systemitem>python-novaclient</systemitem> package.
   </para>
   <procedure id="pro.user.cli.allocate.floating.ips">
    <title>Allocating Floating (Public) IPs to a Project</title>
    <step>
     <para>
      On a shell, source the &ostack; RC file. For details, refer to
      <xref
      linkend="sec.user.cli.rc"/>.
     </para>
    </step>
    <step>
     <para>
      To find pools that provide floating IPs, list all external networks:
     </para>
<screen>neutron net-list --router:external=True</screen>
     <para>
      Among these should be at least one network named
      <literal>floating</literal>.
     </para>
    </step>
    <step>
     <para>
      To allocate a floating IP from this pool to the current project:
     </para>
<screen>neutron floatingip-create <replaceable>FLOAT_NETW_ID_OR_NAME</replaceable>&nbsp;</screen>
     <para>
      To allocate several floating IPs, repeat the command.
     </para>
    </step>
    <step>
     <para>
      To view the floating IP addresses that have been assigned to the
      current project, use the following command:
     </para>
<screen>neutron floatingip-list</screen>
    </step>
    <step>
     <para>
      To release a floating IP from the project, use:
     </para>
<screen>neutron floatingip-delete <replaceable>ID_OF_FLOATING_IP</replaceable>&nbsp;</screen>
    </step>
   </procedure>
   <procedure id="pro.user.cli.assign.floating.ips">
    <title>Assigning Floating (Public) IP Addresses to Instances</title> &ip-assign; <para>
     To assign a floating IP to an instance, you need to know both the ID of
     the floating IP and of the port that has been allocated to the
     instance.
    </para>
    <step>
     <para>
      On a shell, source the &ostack; RC file. For details, refer to
      <xref
       linkend="sec.user.cli.rc"/>.
     </para>
    </step>
    <step>
     <para>
      To find out the port that has been allocated to an instance, proceed
      as follows:
     </para>
     <substeps>
      <step>
       <para>
        List all instances of the project you belong to:
       </para>
<screen>nova list</screen>
       <para>
        The commands shows the running instances, including their ID, their
        name, their status, and their private (and if assigned, their
        public) IP addresses.
       </para>
      </step>
      <step>
       <para>
        Memorize the instance's ID.
       </para>
      </step>
      <step>
       <para>
        Look up the port belonging to the instance ID:
       </para>
<screen>neutron port-list -- device_id <replaceable>INSTANCE_ID</replaceable>&nbsp;</screen>
      </step>
     </substeps>
    </step>
    <step>
     <para>
      To look up the ID of the floating IP address that you want to assign:
     </para>
<screen>neutron floatingip-list</screen>
     <para>
      It lists all floating IPs that belong to the current project,
      including their ID.
     </para>
    </step>
    <step>
     <para>
      Now you can assign a floating IP to the instance with the following
      command:
     </para>
<screen>neutron&nbsp;floatingip-associate&nbsp;<replaceable>ID_OF_FLOATING_IP</replaceable>&nbsp;<replaceable>PORT_ID</replaceable>&nbsp;</screen>
    </step>
    <step>
     <para>
      To check if the floating IP has been assigned, run:
     </para>
<screen>neutron floatingip-show <replaceable>ID_OF_FLOATING_IP</replaceable>&nbsp;</screen>
    </step>
    <step>
     <para>
      To remove the floating IP address from the instance, use:
     </para>
<screen>neutron floatingip-disassociate <replaceable>ID_OF_FLOATING_IP</replaceable>&nbsp;</screen>
    </step>
   </procedure>
<!--taroth 2013-09-04: commenting the former variablelist though it seems much easier to to all
    this with nova commands...-->
<!--<variablelist>
    <varlistentry>
     <term>Listing Pools with Floating IP Addresses </term>
     <listitem>
      <screen>nova floating-ip-pool-list</screen>
      <para> Lists the name of all pools that provide floating IP addresses. </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Allocating a Floating IP Address to the Current Project</term>
     <listitem>
      <screen>nova floating-ip-create</screen>
      <para> The output of the command shows the freshly allocated IP address. If there is more than
       one pool of IP addresses available, you can also specify the pool from which to allocate the
       IP address (optional): </para>
      <screen>floating-ip-create&nbsp;<replaceable>POOL_NAME</replaceable>&nbsp;</screen>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Listing Floating IP Addresses Allocated to the Current
     Project</term>
     <listitem>
      <screen>nova floating-ip-list</screen>
      <para> Lists all floating IP addresses that have been allocated to the current project. If an
       IP is already associated with an instance, the output also shows the instance's IP, the
       instance's fixed IP address and the name of the pool that provides the floating IP address.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Releasing a Floating IP Address from the Current Project</term>
     <listitem>
      <screen>nova floating-ip-delete&nbsp;<replaceable>FLOATING_IP</replaceable>&nbsp;</screen>
      <para> The IP address is put back into the pool of IP addresses that are available for all
       projects. If an IP address is currently assigned to a running instance, it will automatically
       be disassociated from the instance. </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Assigning a Floating IP Address to an Instance</term>
     <listitem>
      <screen>nova add-floating-ip&nbsp;<replaceable>INSTANCE_NAME_OR_ID</replaceable>&nbsp;<replaceable>FLOATING_IP</replaceable>&nbsp;</screen>
      <para> To associate an IP address with an instance, one or multiple floating IP addresses must
       have been allocated to the current project. Check this with
       <command>nova floating-ip-list</command>. In addition, you need to know the instance's name
       (or ID). To look up the instances that belong to the current project, use the
       <command>nova
       list</command> command. </para>
      <para> After assigning the IP with <command>nova add-floating-ip</command>, the instance is
       now publicly available under the respective floating IP address (provided you have also
       configured the security group rules for the instance accordingly). For details, refer to
        <xref linkend="sec.user.dash.inst.access.security"/>. </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Removing a Floating IP Address from an Instance</term>
     <listitem>
      <screen>nova remove-floating-ip&nbsp;<replaceable>INSTANCE_NAME_OR_ID</replaceable>&nbsp;<replaceable>FLOATING_IP</replaceable>&nbsp;</screen>
      <para> To remove a floating IP address from an instance, you need to specify the same
       arguments that you used to assign the IP. </para>
     </listitem>
    </varlistentry>
    </variablelist>-->
  </sect2>
 </sect1>
</chapter>
